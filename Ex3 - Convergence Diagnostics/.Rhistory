betahat <- solve(crossprod(X,X)) %*% crossprod(X,yjY)
covbeta <- solve(crossprod(X,X) + .01 * diag(diag(crossprod(X,X)))) * sigma2e[t-1]
betas[t,] <- mvtnorm::rmvnorm(1, mean = betahat, sigma = covbeta)
# variance
df <- length(yjY) / 2
sumofsq <- sum((yjY - X %*% betas[t,])^2) / 2
sigma2e[t] <- 1 / rgamma(1, df, rate = sumofsq)
# update lambda
for(d in 1:1000){
lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
if (lambda.trial >= lambda.prior[1] & lambda.trial <= lambda.prior[2]) {break}
}
log.trial <- sum(yjll(Y,lambda.trial)) + log(dunif(lambda.trial, lambda.prior[1], lambda.prior[2]))
log.current <- sum(yjll(Y,lambda[t-1])) + log(dunif(lambda[t-1], lambda.prior[1], lambda.prior[2]))
log.iratio <-  log.trial - log.current
logu <- log(runif(1))
if(log.iratio > logu){accept[t] <- 1; lambda[t] <- lambda.trial} else{accept[t] <- 0;  lambda[t] <- lambda[t-1]}
# tune proposal sd
if(t%%tuneinterval == 0 & t <= burnin){
# meanaccept <- mean(accept[(t-tuneinterval):t])
meanaccept <- mean(accept[1:t])
if(meanaccept > .45){mh.sd <- sqrt(mh.sd^2 * 1.2)}
if(meanaccept < .25){mh.sd <- sqrt(mh.sd^2 * .8)}
print(paste0("Iteration = ", t))
print(paste0("lambda | Acceptance rate = ", round(meanaccept,2), " | Proposal SD = ", round(mh.sd, 3)))
}
}
# save samples
lambda.all <- rbind(lambda.all, cbind(c,seq(1:iterations),lambda))
betas.all <- rbind(betas.all, cbind(c,seq(1:iterations),betas))
sigma2e.all <- rbind(sigma2e.all, cbind(c,seq(1:iterations),sigma2e))
accept.all <- rbind(accept.all, cbind(c,seq(1:iterations),accept))
}
# set working directory to the location of this script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read data from working directory
# dat <- read.table(paste0(getwd(),"/alcoholuse2.dat"), na.strings = "999")
# names(dat) <- c("id","male","age","ethnicity","educ","cigage","alcage","alcusemo","cigusemo","drinker")
# fill-in missing values
# datcom <- mice::mice( dat, m = , maxit = 20 )
# datcom <- mice::complete(datcom, action = 1)
# data features
N <- 1000
rsq <- .2
dfchi <- 2
Xbar <- 0
Ybar <- 25
filename <- "df2ybar25xbar0"
centerX <- F
centerY <- F
# simulate data
set.seed(12345)
b1 <- sqrt(-rsq / (rsq - 1))
b0 <- Ybar - b1 * Xbar
betas <- c(b0,b1)
X <- cbind(1,rnorm(N, Xbar, 1))
Y <- X %*% betas + (stats::rchisq( n = N, df = dfchi ) - dfchi) / sqrt(2 * dfchi)
rockchalk::skewness(Y)
rockchalk::kurtosis(Y)
sigm(Y)
sign(Y)
sum(sign(Y))
# set working directory to the location of this script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read data from working directory
# dat <- read.table(paste0(getwd(),"/alcoholuse2.dat"), na.strings = "999")
# names(dat) <- c("id","male","age","ethnicity","educ","cigage","alcage","alcusemo","cigusemo","drinker")
# fill-in missing values
# datcom <- mice::mice( dat, m = , maxit = 20 )
# datcom <- mice::complete(datcom, action = 1)
# data features
N <- 1000
rsq <- .2
dfchi <- 2
Xbar <- 0
Ybar <- 25
filename <- "df2ybar25xbar0"
centerX <- F
centerY <- F
# simulate data
set.seed(12345)
b1 <- sqrt(-rsq / (rsq - 1))
b0 <- Ybar - b1 * Xbar
betas <- c(b0,b1)
X <- cbind(1,rnorm(N, Xbar, 1))
Y <- X %*% betas + (stats::rchisq( n = N, df = dfchi ) - dfchi) / sqrt(2 * dfchi)
rockchalk::skewness(Y)
rockchalk::kurtosis(Y)
# data frame with 1 missing value for mdmb
dat <- datcom <- cbind(Y,X[,2])
write.table(datcom, paste0(getwd(), "/", filename, ".dat"), col.names = F, row.names = F)
dat[1,1] <- 999
dat <- as.data.frame(dat)
names(dat) <- c("Y","X")
dat[dat == 999] <- NA
# configure data
X <- cbind(1, datcom[,2])
Y <- datcom[,1]
# center X for mdmb and my mcmc
if(centerX){
dat$X <- dat$X - Xbar
X[,2] <- X[,2] - Xbar
}
#######################################################
# MY MCMC ALGORITHM
#######################################################
# initialize algorithmic features
iterations <- 30000
burnin <- 20000
chains <- 2
seeds <- c(90291, 90125)
tuneinterval <- 200
lambda.prior <- c(-2,2)
lambda.starts <- c(1,1)
betas.starts <- c(0,0)
sigma2e.starts <- c(1,1)
lambda.all <- NULL
betas.all <- NULL
sigma2e.all <- NULL
accept.all <- NULL
accepts <- c(0,0)
# yeo-johnson log-likelihood
yjll <- function(Y, lambda){
yj.Y <- VGAM::yeo.johnson(Y, lambda = lambda)
ll.pt1 <- sum(dnorm(yj.Y - X %*% betas[t,], 0, sqrt(sigma2e[t]), log = T))
ll.pt2 <- (lambda - 1) * sum(sign(Y) * log(abs(Y) + 1))
ll <- cbind(ll.pt1,ll.pt2)
return(ll)
}
# gibbs sampler
for(c in 1:chains){
# initialize parameters
set.seed(seeds[c])
mh.sd <- .05
lambda <- matrix(lambda.starts[c], iterations)
betas <- matrix(betas.starts[c], ncol = ncol(X), nrow = iterations)
sigma2e <- matrix(sigma2e.starts[c], iterations)
accept <- matrix(0, iterations)
for(t in 2:iterations){
# t <- 2
# print iteration history
if(t > burnin & t %% 100 == 0){print(paste0("Iteration = " , t))}
# transform Y
yjY <- VGAM::yeo.johnson(Y, lambda = lambda[t-1])
# regression coefficients
betahat <- solve(crossprod(X,X)) %*% crossprod(X,yjY)
covbeta <- solve(crossprod(X,X) + .01 * diag(diag(crossprod(X,X)))) * sigma2e[t-1]
betas[t,] <- mvtnorm::rmvnorm(1, mean = betahat, sigma = covbeta)
# variance
df <- length(yjY) / 2
sumofsq <- sum((yjY - X %*% betas[t,])^2) / 2
sigma2e[t] <- 1 / rgamma(1, df, rate = sumofsq)
# update lambda
# for(d in 1:1000){
#   lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
#   if (lambda.trial >= lambda.prior[1] & lambda.trial <= lambda.prior[2]) {break}
# }
# log.trial <- sum(yjll(Y,lambda.trial)) + log(dunif(lambda.trial, lambda.prior[1], lambda.prior[2]))
# log.current <- sum(yjll(Y,lambda[t-1])) + log(dunif(lambda[t-1], lambda.prior[1], lambda.prior[2]))
lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
log.trial <- sum(yjll(Y,lambda.trial)) + dnorm(lambda.trial, 0, 3, log = T)
log.current <- sum(yjll(Y,lambda[t-1])) + dnorm(lambda[t-1], 0, 3, log = T)
log.iratio <-  log.trial - log.current
logu <- log(runif(1))
if(log.iratio > logu){accept[t] <- 1; lambda[t] <- lambda.trial} else{accept[t] <- 0;  lambda[t] <- lambda[t-1]}
# tune proposal sd
if(t%%tuneinterval == 0 & t <= burnin){
# meanaccept <- mean(accept[(t-tuneinterval):t])
meanaccept <- mean(accept[1:t])
if(meanaccept > .45){mh.sd <- sqrt(mh.sd^2 * 1.2)}
if(meanaccept < .25){mh.sd <- sqrt(mh.sd^2 * .8)}
print(paste0("Iteration = ", t))
print(paste0("lambda | Acceptance rate = ", round(meanaccept,2), " | Proposal SD = ", round(mh.sd, 3)))
}
}
# save samples
lambda.all <- rbind(lambda.all, cbind(c,seq(1:iterations),lambda))
betas.all <- rbind(betas.all, cbind(c,seq(1:iterations),betas))
sigma2e.all <- rbind(sigma2e.all, cbind(c,seq(1:iterations),sigma2e))
accept.all <- rbind(accept.all, cbind(c,seq(1:iterations),accept))
}
params <- cbind(betas.all, sigma2e.all, lambda.all)
colnames(params) <- c("c","i","b0","b1","c2","i2","resvar","c3","c4","lambda")
chain1 <- coda::mcmc(params[params[,2] > burnin & params[,1] == 1, c(1,2,3,4,7,10)])
chain2 <- coda::mcmc(params[params[,2] > burnin & params[,1] == 2, c(1,2,3,4,7,10)])
coda::densplot(chain1, show.obs = TRUE, type="l")
# overall acceptance
mean(accept.all[accept.all[,2] > burnin, 3])
summary <- matrix(0, nrow = 4, ncol = 5)
rownames(summary) <- c("B0", "B1", "res. var.", "lambda")
colnames(summary) <- c("Mean", "StdDev", "2.5%", "50%", "97.5%")
# summarize posterior distributiona
params <- cbind(betas, sigma2e, lambda)
for(p in 1:length(rownames(summary))){
summary[p,1] <- mean(params[(burnin+1):iterations,p])
summary[p,2] <- sd(params[(burnin+1):iterations,p])
summary[p,3:5] <- quantile(params[(burnin+1):iterations,p], c(.025, .50, .975))
plot(density(params[(burnin+1):iterations,p]), main = rownames(summary)[p], xlab = "Parameter Value")
}
print(paste0("Posterior Distribution Summary from ", iterations - burnin, " Iterations:"))
print(round(summary, 3))
print(round(mdmbresults, 3))
# mdmb models
mod.x <- list("model" = "linreg", "formula" = X ~ 1)
mod.y <- list("model" = "yjtreg", "formula" = Y ~ 1 + X)
mod.xs <- list(X = mod.x)
set.seed(seeds[1])
yjtreg.1 <- mdmb::frm_fb(dat = dat, dep = mod.y, ind = mod.xs, verbose = T, burnin = burnin, iter = iterations, Nsave = iterations)
set.seed(seeds[2])
yjtreg.2 <- mdmb::frm_fb(dat = dat, dep = mod.y, ind = mod.xs, verbose = T, burnin = burnin, iter = iterations, Nsave = iterations)
summary(yjtreg.1)
# set working directory to the location of this script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read data from working directory
# dat <- read.table(paste0(getwd(),"/alcoholuse2.dat"), na.strings = "999")
# names(dat) <- c("id","male","age","ethnicity","educ","cigage","alcage","alcusemo","cigusemo","drinker")
# fill-in missing values
# datcom <- mice::mice( dat, m = , maxit = 20 )
# datcom <- mice::complete(datcom, action = 1)
# data features
N <- 1000
rsq <- .2
dfchi <- 2
Xbar <- 25
Ybar <- 0
filename <- "df2ybar0xbar25"
centerX <- T
# simulate data
set.seed(12345)
b1 <- sqrt(-rsq / (rsq - 1))
b0 <- Ybar - b1 * Xbar
betas <- c(b0,b1)
X <- cbind(1,rnorm(N, Xbar, 1))
Y <- X %*% betas + (stats::rchisq( n = N, df = dfchi ) - dfchi) / sqrt(2 * dfchi)
rockchalk::skewness(Y)
rockchalk::kurtosis(Y)
# data frame with 1 missing value for mdmb
dat <- datcom <- cbind(Y,X[,2])
write.table(datcom, paste0(getwd(), "/", filename, ".dat"), col.names = F, row.names = F)
dat[1,1] <- 999
dat <- as.data.frame(dat)
names(dat) <- c("Y","X")
dat[dat == 999] <- NA
# configure data
X <- cbind(1, datcom[,2])
Y <- datcom[,1]
# center X for mdmb and my mcmc
if(centerX){
dat$X <- dat$X - Xbar
X[,2] <- X[,2] - Xbar
}
#######################################################
# MY MCMC ALGORITHM
#######################################################
# initialize algorithmic features
iterations <- 20000
burnin <- 10000
chains <- 2
tuneinterval <- 200
lambda.prior <- c(-2,2)
lambda.starts <- c(0,1)
betas.starts <- c(0,.5)
sigma2e.starts <- c(1,3)
mh.sd <- .10
lambda.all <- NULL
betas.all <- NULL
sigma2e.all <- NULL
accept.all <- NULL
accepts <- c(0,0)
# yeo-johnson log-likelihood
yjll <- function(Y, lambda){
yj.Y <- mdmb::yj_trafo(Y, lambda = lambda)
ll.pt1 <- sum(dnorm(yj.Y - X %*% betas[t,], 0, sqrt(sigma2e[t]), log = T))
ll.pt2 <- (lambda - 1) * sum(sign(Y) * log(abs(Y) + 1))
ll <- cbind(ll.pt1,ll.pt2)
return(ll)
}
# gibbs sampler
for(c in 1:chains){
# initialize parameters
lambda <- matrix(lambda.starts[c], iterations)
betas <- matrix(betas.starts[c], ncol = ncol(X), nrow = iterations)
sigma2e <- matrix(sigma2e.starts[c], iterations)
accept <- matrix(0, iterations)
for(t in 2:iterations){
# t <- 2
# print iteration history
if(t > burnin & t %% 100 == 0){print(paste0("Iteration = " , t))}
# transform Y
yjY <- mdmb::yj_trafo(Y, lambda = lambda[t-1])
# regression coefficients
betahat <- solve(crossprod(X,X)) %*% crossprod(X,yjY)
covbeta <- solve(crossprod(X,X) + .01 * diag(diag(crossprod(X,X)))) * sigma2e[t-1]
betas[t,] <- mvtnorm::rmvnorm(1, mean = betahat, sigma = covbeta)
# variance
df <- length(yjY) / 2
sumofsq <- sum((yjY - X %*% betas[t,])^2) / 2
sigma2e[t] <- 1 / rgamma(1, df, rate = sumofsq)
# update lambda
for(d in 1:1000){
lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
if (lambda.trial >= lambda.prior[1] & lambda.trial <= lambda.prior[2]) {break}
}
log.trial <- sum(yjll(Y,lambda.trial)) + log(dunif(lambda.trial, lambda.prior[1], lambda.prior[2]))
log.current <- sum(yjll(Y,lambda[t-1])) + log(dunif(lambda[t-1], lambda.prior[1], lambda.prior[2]))
log.iratio <-  log.trial - log.current
logu <- log(runif(1))
if(log.iratio > logu){accept[t] <- 1; lambda[t] <- lambda.trial} else{accept[t] <- 0;  lambda[t] <- lambda[t-1]}
# tune proposal sd
if(t%%tuneinterval == 0 & t <= burnin){
meanaccept <- mean(accept[(t-tuneinterval):t])
if(meanaccept > .45){mh.sd <- sqrt(mh.sd^2 * 1.2)}
if(meanaccept < .25){mh.sd <- sqrt(mh.sd^2 * .8)}
print(paste0("Iteration = ", t))
print(paste0("lambda | Acceptance rate = ", round(meanaccept,2), " | Proposal SD = ", round(mh.sd, 3)))
}
}
# save samples
lambda.all <- rbind(lambda.all, cbind(c,seq(1:iterations),lambda))
betas.all <- rbind(betas.all, cbind(c,seq(1:iterations),betas))
sigma2e.all <- rbind(sigma2e.all, cbind(c,seq(1:iterations),sigma2e))
accept.all <- rbind(accept.all, cbind(c,seq(1:iterations),accept))
}
# overall acceptance
mean(accept.all[accept.all[,2] > burnin, 3])
# summarize posterior distributions
summary <- matrix(0, nrow = 4, ncol = 5)
rownames(summary) <- c("B0", "B1", "res. var.", "lambda")
colnames(summary) <- c("Mean", "StdDev", "2.5%", "50%", "97.5%")
# summarize posterior distributiona
params <- cbind(betas, sigma2e, lambda)
for(p in 1:length(rownames(summary))){
summary[p,1] <- mean(params[(burnin+1):iterations,p])
summary[p,2] <- sd(params[(burnin+1):iterations,p])
summary[p,3:5] <- quantile(params[(burnin+1):iterations,p], c(.025, .50, .975))
plot(density(params[(burnin+1):iterations,p]), main = rownames(summary)[p], xlab = "Parameter Value")
}
print(paste0("Posterior Distribution Summary from ", iterations - burnin, " Iterations:"))
print(round(summary, 3))
# set working directory to the location of this script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# read data from working directory
# dat <- read.table(paste0(getwd(),"/alcoholuse2.dat"), na.strings = "999")
# names(dat) <- c("id","male","age","ethnicity","educ","cigage","alcage","alcusemo","cigusemo","drinker")
# fill-in missing values
# datcom <- mice::mice( dat, m = , maxit = 20 )
# datcom <- mice::complete(datcom, action = 1)
# data features
N <- 1000
rsq <- .2
dfchi <- 2
Xbar <- 0
Ybar <- 25
filename <- "df2ybar25xbar0"
centerX <- F
centerY <- F
# simulate data
set.seed(12345)
b1 <- sqrt(-rsq / (rsq - 1))
b0 <- Ybar - b1 * Xbar
betas <- c(b0,b1)
X <- cbind(1,rnorm(N, Xbar, 1))
Y <- X %*% betas + (stats::rchisq( n = N, df = dfchi ) - dfchi) / sqrt(2 * dfchi)
rockchalk::skewness(Y)
rockchalk::kurtosis(Y)
summary(Y)
Y <- Y - 22
# data frame with 1 missing value for mdmb
dat <- datcom <- cbind(Y,X[,2])
write.table(datcom, paste0(getwd(), "/", filename, ".dat"), col.names = F, row.names = F)
dat[1,1] <- 999
dat <- as.data.frame(dat)
names(dat) <- c("Y","X")
dat[dat == 999] <- NA
colMeans(X)
# configure data
X <- cbind(1, datcom[,2])
Y <- datcom[,1]
# center X for mdmb and my mcmc
if(centerX){
dat$X <- dat$X - Xbar
X[,2] <- X[,2] - Xbar
}
#######################################################
# MY MCMC ALGORITHM
#######################################################
# initialize algorithmic features
iterations <- 30000
burnin <- 20000
chains <- 2
seeds <- c(90291, 90125)
tuneinterval <- 200
lambda.prior <- c(-2,2)
lambda.starts <- c(1,1)
betas.starts <- c(0,0)
sigma2e.starts <- c(1,1)
lambda.all <- NULL
betas.all <- NULL
sigma2e.all <- NULL
accept.all <- NULL
accepts <- c(0,0)
# yeo-johnson log-likelihood
yjll <- function(Y, lambda){
yj.Y <- VGAM::yeo.johnson(Y, lambda = lambda)
ll.pt1 <- sum(dnorm(yj.Y - X %*% betas[t,], 0, sqrt(sigma2e[t]), log = T))
ll.pt2 <- (lambda - 1) * sum(sign(Y) * log(abs(Y) + 1))
ll <- cbind(ll.pt1,ll.pt2)
return(ll)
}
# gibbs sampler
for(c in 1:chains){
# initialize parameters
set.seed(seeds[c])
mh.sd <- .05
lambda <- matrix(lambda.starts[c], iterations)
betas <- matrix(betas.starts[c], ncol = ncol(X), nrow = iterations)
sigma2e <- matrix(sigma2e.starts[c], iterations)
accept <- matrix(0, iterations)
for(t in 2:iterations){
# t <- 2
# print iteration history
if(t > burnin & t %% 100 == 0){print(paste0("Iteration = " , t))}
# transform Y
yjY <- VGAM::yeo.johnson(Y, lambda = lambda[t-1])
# regression coefficients
betahat <- solve(crossprod(X,X)) %*% crossprod(X,yjY)
covbeta <- solve(crossprod(X,X) + .01 * diag(diag(crossprod(X,X)))) * sigma2e[t-1]
betas[t,] <- mvtnorm::rmvnorm(1, mean = betahat, sigma = covbeta)
# variance
df <- length(yjY) / 2
sumofsq <- sum((yjY - X %*% betas[t,])^2) / 2
sigma2e[t] <- 1 / rgamma(1, df, rate = sumofsq)
# update lambda
# for(d in 1:1000){
#   lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
#   if (lambda.trial >= lambda.prior[1] & lambda.trial <= lambda.prior[2]) {break}
# }
# log.trial <- sum(yjll(Y,lambda.trial)) + log(dunif(lambda.trial, lambda.prior[1], lambda.prior[2]))
# log.current <- sum(yjll(Y,lambda[t-1])) + log(dunif(lambda[t-1], lambda.prior[1], lambda.prior[2]))
lambda.trial <- rnorm(1, lambda[t-1], mh.sd)
log.trial <- sum(yjll(Y,lambda.trial)) + dnorm(lambda.trial, 0, 3, log = T)
log.current <- sum(yjll(Y,lambda[t-1])) + dnorm(lambda[t-1], 0, 3, log = T)
log.iratio <-  log.trial - log.current
logu <- log(runif(1))
if(log.iratio > logu){accept[t] <- 1; lambda[t] <- lambda.trial} else{accept[t] <- 0;  lambda[t] <- lambda[t-1]}
# tune proposal sd
if(t%%tuneinterval == 0 & t <= burnin){
meanaccept <- mean(accept[(t-tuneinterval):t])
# meanaccept <- mean(accept[1:t])
if(meanaccept > .45){mh.sd <- sqrt(mh.sd^2 * 1.25)}
if(meanaccept < .25){mh.sd <- sqrt(mh.sd^2 * .75)}
print(paste0("Iteration = ", t))
print(paste0("lambda | Acceptance rate = ", round(meanaccept,2), " | Proposal SD = ", round(mh.sd, 3)))
}
}
# save samples
lambda.all <- rbind(lambda.all, cbind(c,seq(1:iterations),lambda))
betas.all <- rbind(betas.all, cbind(c,seq(1:iterations),betas))
sigma2e.all <- rbind(sigma2e.all, cbind(c,seq(1:iterations),sigma2e))
accept.all <- rbind(accept.all, cbind(c,seq(1:iterations),accept))
}
# overall acceptance
mean(accept.all[accept.all[,2] > burnin, 3])
params <- cbind(betas.all, sigma2e.all, lambda.all)
colnames(params) <- c("c","i","b0","b1","c2","i2","resvar","c3","c4","lambda")
chain1 <- coda::mcmc(params[params[,2] > burnin & params[,1] == 1, c(1,2,3,4,7,10)])
chain2 <- coda::mcmc(params[params[,2] > burnin & params[,1] == 2, c(1,2,3,4,7,10)])
coda::densplot(chain1, show.obs = TRUE, type="l")
coda::gelman.diag(list(chain1,chain2), confidence = 0.95, multivariate = F)
summary <- matrix(0, nrow = 4, ncol = 5)
rownames(summary) <- c("B0", "B1", "res. var.", "lambda")
colnames(summary) <- c("Mean", "StdDev", "2.5%", "50%", "97.5%")
# summarize posterior distributiona
params <- cbind(betas, sigma2e, lambda)
for(p in 1:length(rownames(summary))){
summary[p,1] <- mean(params[(burnin+1):iterations,p])
summary[p,2] <- sd(params[(burnin+1):iterations,p])
summary[p,3:5] <- quantile(params[(burnin+1):iterations,p], c(.025, .50, .975))
plot(density(params[(burnin+1):iterations,p]), main = rownames(summary)[p], xlab = "Parameter Value")
}
print(paste0("Posterior Distribution Summary from ", iterations - burnin, " Iterations:"))
print(round(summary, 3))
dat <- read.table(paste0(getwd(),"/alcoholuse2.dat"), na.strings = "999")
names(dat) <- c("id","male","age","ethnicity","educ","cigage","alcage","alcusemo","cigusemo","drinker")
summary(age)
summary(dat$age)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
chain1 <- read.table(paste0(getwd(), "/iter1.dat"))
View(chain1)
chain1 <- read.table(paste0(getwd(), "/iter1.dat"))[5]
View(chain1)
chain1 <- read.table(paste0(getwd(), "/iter1.dat"))[5]
chain2 <- read.table(paste0(getwd(), "/iter2.dat"))[5]
coda::densplot(chain1, show.obs = TRUE, type="l")
chains <- coda::as.mcmc(cbind(chain1,chain2))
coda::densplot(chains, show.obs = TRUE, type="l")
coda::gelman.diag(chains, confidence = 0.95, multivariate = F)
coda::gelman.diag(list(chain1,chain2), confidence = 0.95, multivariate = F)
chains <- coda::as.mcmc.list(chain1,chain2)
chain1 <- coda::as.mcmc(read.table(paste0(getwd(), "/iter1.dat"))[5])
chain2 <- coda::as.mcmc(read.table(paste0(getwd(), "/iter2.dat"))[5])
chains <- coda::as.mcmc.list(chain1,chain2)
coda::densplot(chains, show.obs = TRUE, type="l")
coda::densplot(chains, show.obs = TRUE, type="l")
coda::gelman.diag(list(chain1,chain2), confidence = 0.95, multivariate = F)
coda::effectiveSize(chains)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
chain1 <- coda::as.mcmc(read.table(paste0(getwd(), "/iter1.dat"))[5])
chain2 <- coda::as.mcmc(read.table(paste0(getwd(), "/iter2.dat"))[5])
chains <- coda::as.mcmc.list(chain1,chain2)
coda::effectiveSize(chains)
